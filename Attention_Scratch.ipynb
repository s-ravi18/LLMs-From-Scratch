{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN23XaEs70kwFV64P6rkts9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-ravi18/LLMs-From-Scratch/blob/main/Attention_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1Aki7Rh379S"
      },
      "outputs": [],
      "source": [
        "# Input Embeddings\n",
        "#    ↓\n",
        "# Multi-Head Self Attention\n",
        "#    ↓ (+ residual)\n",
        "# LayerNorm\n",
        "#    ↓\n",
        "# Feed Forward Network\n",
        "#    ↓ (+ residual)\n",
        "# LayerNorm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "tHzmgI5F3-SZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialisation of parameters\n"
      ],
      "metadata": {
        "id": "vHFJghrDjDlI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 784\n",
        "vocab_size = 50000\n",
        "embed_layer = nn.Embedding(vocab_size, embed_size)\n",
        "## Embedding layer --> dimension size is 784"
      ],
      "metadata": {
        "id": "NlZVxXyOjMw5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Basic text preprocessing:\n",
        "    - Lowercase\n",
        "    - Remove URLs\n",
        "    - Remove HTML tags\n",
        "    - Remove punctuation\n",
        "    - Remove extra whitespaces\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "ZqAh-jTZj2-5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = [\"The girl is sitting in the room.\"]\n"
      ],
      "metadata": {
        "id": "pPGUVb54jmw3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text = clean_text(sample[0])"
      ],
      "metadata": {
        "id": "73g1xn3yk2TE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "khEqWjfJlAex",
        "outputId": "fd0285b1-3e63-4d91-cc57-ede30799ec8b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the girl is sitting in the room'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_to_id = {i:ind for ind, i in enumerate(clean_text.split(' '))}\n",
        "id_to_token = {ind:i for ind, i in enumerate(clean_text.split(' '))}"
      ],
      "metadata": {
        "id": "5W-IqaNrkJa7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text_tokenised = torch.tensor([token_to_id[i] for i in clean_text.split(' ')])"
      ],
      "metadata": {
        "id": "oB-dhvKJlK9Z"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text_tokenised"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HnPKnvQld_0",
        "outputId": "43c9a8b3-de22-4fdd-d41a-4e3703281654"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = embed_layer(clean_text_tokenised)"
      ],
      "metadata": {
        "id": "XWvBBu4Nj-pA"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zMbO6IelzTy",
        "outputId": "bbe340d8-cb9b-4195-cfca-ebcf2ad5e6e1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.4535e+00,  1.4793e-03, -6.2106e-01,  ..., -2.3350e-01,\n",
              "         -1.1471e+00,  4.8996e-01],\n",
              "        [-1.5351e+00, -2.1321e-01,  6.8851e-02,  ..., -2.0872e-01,\n",
              "          6.7512e-01, -3.2629e-01],\n",
              "        [-1.0183e+00, -5.0319e-01,  1.7632e-01,  ...,  2.0079e-02,\n",
              "         -5.8421e-01, -2.9888e-01],\n",
              "        ...,\n",
              "        [ 1.9812e+00, -1.0320e+00,  8.9632e-01,  ...,  1.0867e+00,\n",
              "         -4.7835e-01,  1.1864e+00],\n",
              "        [ 1.4535e+00,  1.4793e-03, -6.2106e-01,  ..., -2.3350e-01,\n",
              "         -1.1471e+00,  4.8996e-01],\n",
              "        [ 4.0768e-01, -1.0015e+00,  3.6183e-02,  ...,  1.5646e+00,\n",
              "         -1.5207e-01,  1.1371e+00]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1, batch_size = 5, max_seq_length, embedding_size"
      ],
      "metadata": {
        "id": "kikLNuVoo8fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Simple attention layer without positional encoding;\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class attention_layer(nn.Module):\n",
        "\n",
        "  def __init__(self, n_heads, embed_size):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.n_heads = n_heads\n",
        "    self.attn_size = embed_size // n_heads\n",
        "    self.scale = self.attn_size ** 0.5\n",
        "    self.embed_size = embed_size\n",
        "\n",
        "    ## Ensuring He initialisation;\n",
        "    # Linear layers to project input → Q, K, V\n",
        "    self.W_Q = nn.Linear(self.embed_size, self.embed_size)\n",
        "    self.W_K = nn.Linear(self.embed_size, self.embed_size)\n",
        "    self.W_V = nn.Linear(self.embed_size, self.embed_size)\n",
        "\n",
        "    # Output linear projection\n",
        "    self.W_O = nn.Linear(self.embed_size, self.embed_size)\n",
        "\n",
        "  # def reset_parameters(self):\n",
        "  #     # Apply He initialization\n",
        "  #     init.kaiming_normal_(self.w, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "\n",
        "  def forward(self, X):  ### X --> (batch_size, seq_len, embed_size)\n",
        "\n",
        "    batch_size = X.shape[0]\n",
        "    seq_len = X.shape[1]\n",
        "\n",
        "    K = self.W_K(X)  ## batch_size, seq_len, embed_size\n",
        "    Q = self.W_Q(X)\n",
        "    V = self.W_V(X)\n",
        "\n",
        "    ## Reshape + transpose;\n",
        "\n",
        "    K = K.reshape(batch_size, seq_len, self.n_heads, self.attn_size).transpose(-3, -2)  ## batch_size, seq_len, n_heads, attn_size ---> batch_size, n_heads, seq_len, attn_size\n",
        "    Q = Q.reshape(batch_size, seq_len, self.n_heads, self.attn_size).transpose(-3, -2)\n",
        "    V = V.reshape(batch_size, seq_len, self.n_heads, self.attn_size).transpose(-3, -2)\n",
        "\n",
        "    ## calculating attention scores for the batch; batch_size, seq_len, seq_len\n",
        "\n",
        "    att_scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale\n",
        "\n",
        "    ## batch_size, n_heads, seq_len, seq_len -->\n",
        "\n",
        "    ## Softmax,\n",
        "    weights = F.softmax(att_scores, dim=-1)  ## batch_size, n_heads, seq_len, seq_len\n",
        "\n",
        "    ## V --> batch_size, n_heads, seq_len, attn_size\n",
        "    ## weights --> batch_size, n_heads, seq_len, seq_len\n",
        "    V = torch.matmul(weights, V)  ## batch_size, n_heads, seq_len, attn_size\n",
        "\n",
        "\n",
        "    ## Reshaping the output - to concatenate the heads;\n",
        "    V = V.transpose(1, 2).reshape(batch_size, seq_len, -1)  ## batch_size, seq_len, embed_size\n",
        "\n",
        "    ## Forward\n",
        "    V = self.W_O(V)\n",
        "\n",
        "    return V\n",
        "\n"
      ],
      "metadata": {
        "id": "k0YEsB0hmiyH"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_size, n_heads, hidden_dim):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    ## Embedding Generation;\n",
        "    self.e1 = nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "    ## Attention layers - Encoder;\n",
        "    self.multi_head_count = 1   ## 12 in the case of GPT\n",
        "    self.attn_layer = nn.ModuleList([attention_layer(n_heads, embed_size) for i in range(self.multi_head_count)])\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(embed_size, hidden_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(hidden_dim, embed_size),\n",
        "    )\n",
        "\n",
        "    self.ln1 = nn.LayerNorm(embed_size)\n",
        "    self.ln2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    ## Convert into its embedding;\n",
        "    X = self.e1(X)\n",
        "\n",
        "    for layer in self.attn_layer:\n",
        "      X = layer(X) + X  ##\n",
        "      X = self.ln1(X)\n",
        "\n",
        "    X = self.net(X) + X ## feed forward NN\n",
        "    X = self.ln2(X)\n",
        "\n",
        "    return X\n",
        "\n"
      ],
      "metadata": {
        "id": "gtjAPkir3-Uc"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CzjNHX8WVeFh"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_heads = 8\n",
        "hidden_dim = 2048\n",
        "embed_size = 784\n",
        "\n",
        "encoder = Encoder(vocab_size, embed_size, n_heads, hidden_dim)"
      ],
      "metadata": {
        "id": "Rk2SOPPkViLg"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zFz4Bx16W-xl"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = clean_text_tokenised"
      ],
      "metadata": {
        "id": "_i3P0h5MW-0B"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.view(1, -1)"
      ],
      "metadata": {
        "id": "kZfI6HBGXCn2"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOJieCyWXCqi",
        "outputId": "f6bebba4-c7e9-4747-b9f4-8fb47ab025b2"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8O8ZGEfXTkw"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN0HbGipXTnT",
        "outputId": "5eafbc90-64ea-45f7-8c81-9ceb4da2fe9c"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.0093,  0.2547,  0.4176,  ...,  0.3115,  0.2546, -0.0553],\n",
              "         [ 0.6095, -1.1749,  0.9938,  ...,  1.7051, -1.7248, -0.4859],\n",
              "         [ 0.0431,  0.5581, -2.1931,  ...,  0.8225, -0.4722, -0.2956],\n",
              "         ...,\n",
              "         [ 0.8295, -0.3770,  0.3906,  ..., -0.3801, -0.9384,  0.1321],\n",
              "         [ 1.0093,  0.2547,  0.4176,  ...,  0.3115,  0.2546, -0.0553],\n",
              "         [ 0.9119,  0.0678, -0.9759,  ..., -2.1345, -0.6113, -0.0054]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LfS4cVSEViOA"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## WIP; Need to implement the Masked Self Attention for the decoder.\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_size, n_heads, hidden_dim):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    ## Attention layers - Encoder;\n",
        "    self.multi_head_count = 1   ## 12 in the case of GPT\n",
        "    self.attn_layer = nn.ModuleList([attention_layer(n_heads, embed_size) for i in range(self.multi_head_count)])\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(embed_size, hidden_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(hidden_dim, embed_size),\n",
        "    )\n",
        "\n",
        "    self.ln1 = nn.LayerNorm(embed_size)\n",
        "\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    for layer in self.attn_layer:\n",
        "      X = layer(X) + X  ##\n",
        "      X = self.ln1(X)\n",
        "\n",
        "    X = self.net(X)  ## feed forward NN\n",
        "    X = self.ln1(X)\n",
        "\n",
        "    return X\n",
        "\n"
      ],
      "metadata": {
        "id": "cJvVAwcKGY6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[[1,2,3],\n",
        "                  [1,2,3]],\n",
        "                 [[1,2,3],\n",
        "                  [1,2,3]]], dtype = float)"
      ],
      "metadata": {
        "id": "TLZeGDHUGY8n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "8QEtlYBhGY-n"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(t, dim=-2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiqJDnRZGyDN",
        "outputId": "538ad7ab-5a91-4ea7-af00-e8dfb5f04e40"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.5000, 0.5000, 0.5000],\n",
              "         [0.5000, 0.5000, 0.5000]],\n",
              "\n",
              "        [[0.5000, 0.5000, 0.5000],\n",
              "         [0.5000, 0.5000, 0.5000]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.0900 + 0.2447 + 0.6652"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb4oOIzTHItJ",
        "outputId": "50e77191-281e-4cef-ad62-a7f98a11d21f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vmEylXlLHNhD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}