{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOh8gQ/fOwIriuynk1sMuzF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-ravi18/LLMs-From-Scratch/blob/main/Attention_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1Aki7Rh379S"
      },
      "outputs": [],
      "source": [
        "# Input Embeddings\n",
        "#    ↓\n",
        "# Multi-Head Self Attention\n",
        "#    ↓ (+ residual)\n",
        "# LayerNorm\n",
        "#    ↓\n",
        "# Feed Forward Network\n",
        "#    ↓ (+ residual)\n",
        "# LayerNorm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "tHzmgI5F3-SZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialisation of parameters\n"
      ],
      "metadata": {
        "id": "vHFJghrDjDlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 784\n",
        "vocab_size = 50000\n",
        "e = nn.Embedding(vocab_size, embed_size)\n",
        "## Embedding layer --> dimension size is 784"
      ],
      "metadata": {
        "id": "NlZVxXyOjMw5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Basic text preprocessing:\n",
        "    - Lowercase\n",
        "    - Remove URLs\n",
        "    - Remove HTML tags\n",
        "    - Remove punctuation\n",
        "    - Remove extra whitespaces\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "ZqAh-jTZj2-5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = [\"The girl is sitting in the room.\"]\n"
      ],
      "metadata": {
        "id": "pPGUVb54jmw3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text = clean_text(sample[0])"
      ],
      "metadata": {
        "id": "73g1xn3yk2TE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "khEqWjfJlAex",
        "outputId": "8f6e92fa-79b3-42f3-b382-ca94d96090c4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the girl is sitting in the room'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_to_id = {i:ind for ind, i in enumerate(clean_text.split(' '))}\n",
        "id_to_token = {ind:i for ind, i in enumerate(clean_text.split(' '))}"
      ],
      "metadata": {
        "id": "5W-IqaNrkJa7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text_tokenised = torch.tensor([token_to_id[i] for i in clean_text.split(' ')])"
      ],
      "metadata": {
        "id": "oB-dhvKJlK9Z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text_tokenised"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HnPKnvQld_0",
        "outputId": "f669d221-0dbc-4120-c180-04812dd6b2fe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = e(clean_text_tokenised)"
      ],
      "metadata": {
        "id": "XWvBBu4Nj-pA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zMbO6IelzTy",
        "outputId": "7da81a20-00a4-4348-f005-bca55f060036"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.4831e-01, -1.7372e-01,  1.6457e+00,  ..., -1.2697e+00,\n",
              "         -3.5481e-04, -2.0473e+00],\n",
              "        [ 6.4851e-01,  7.5638e-01, -5.0419e-01,  ..., -7.6762e-01,\n",
              "         -1.0876e-01,  3.9190e-01],\n",
              "        [ 1.3516e+00, -1.0577e+00, -2.3979e+00,  ...,  4.4797e-01,\n",
              "         -5.1802e-01, -7.5275e-01],\n",
              "        ...,\n",
              "        [ 5.1763e-01,  5.5260e-01,  1.1672e+00,  ...,  4.0926e-01,\n",
              "          3.6867e+00,  2.0453e-01],\n",
              "        [ 3.4831e-01, -1.7372e-01,  1.6457e+00,  ..., -1.2697e+00,\n",
              "         -3.5481e-04, -2.0473e+00],\n",
              "        [-1.1794e-01,  1.4702e+00, -3.1845e-01,  ..., -2.2812e-03,\n",
              "          1.9396e+00,  1.6642e-01]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1, batch_size = 5, max_seq_length, embedding_size"
      ],
      "metadata": {
        "id": "kikLNuVoo8fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Simple attention layer without positional encoding;\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class attention_layer(nn.Module):\n",
        "\n",
        "  def __init__(self, n_heads, embed_size):\n",
        "\n",
        "    self.reset_parameters()\n",
        "    self.n_heads = n_heads\n",
        "    self.attn_size = embed_size // n_heads\n",
        "    self.scale = self.attn_size ** 0.5\n",
        "    self.embed_size = embed_size\n",
        "\n",
        "    ## Ensuring He initialisation;\n",
        "    # Linear layers to project input → Q, K, V\n",
        "    self.W_Q = nn.Linear(self.embed_size, self.embed_size)\n",
        "    self.W_K = nn.Linear(self.embed_size, self.embed_size)\n",
        "    self.W_V = nn.Linear(self.embed_size, self.embed_size)\n",
        "\n",
        "    # Output linear projection\n",
        "    self.W_O = nn.Linear(self.embed_size, self.embed_size)\n",
        "\n",
        "  # def reset_parameters(self):\n",
        "  #     # Apply He initialization\n",
        "  #     init.kaiming_normal_(self.w, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "\n",
        "  def forward(self, X):  ### X --> (batch_size, seq_len, embed_size)\n",
        "\n",
        "    batch_size = X.shape[0]\n",
        "    seq_len = X.shape[1]\n",
        "\n",
        "    K = X @ self.Wk  ## batch_size, seq_len, embed_size\n",
        "    Q = X @ self.Wq\n",
        "    V = X @ self.Wv\n",
        "\n",
        "    ## Reshape + transpose;\n",
        "\n",
        "    K = K.reshape(batch_size, seq_len, self.n_heads, self.attn_size).transpose(-3, -2)  ## batch_size, seq_len, n_heads, attn_size ---> batch_size, n_heads, seq_len, attn_size\n",
        "    Q = Q.reshape(batch_size, seq_len, self.n_heads, self.attn_size).transpose(-3, -2)\n",
        "    V = V.reshape(batch_size, seq_len, self.n_heads, self.attn_size).transpose(-3, -2)\n",
        "\n",
        "    ## calculating attention scores for the batch; batch_size, seq_len, seq_len\n",
        "\n",
        "    att_scores = torch.matmul(Q, K.transpose(-2, -1)) // self.scale\n",
        "\n",
        "    ## batch_size, n_heads, seq_len, seq_len -->\n",
        "\n",
        "    ## Softmax,\n",
        "    weights = F.softmax(att_scores, dim=-1)  ## batch_size, n_heads, seq_len, seq_len\n",
        "\n",
        "    ## V --> batch_size, n_heads, seq_len, attn_size\n",
        "    ## weights --> batch_size, n_heads, seq_len, seq_len\n",
        "    V = torch.matmul(weights, V)  ## batch_size, n_heads, seq_len, attn_size\n",
        "\n",
        "\n",
        "    ## Reshaping the output - to concatenate the heads;\n",
        "    V = V.transpose(1, 2).reshape(batch_size, seq_len, -1)  ## batch_size, seq_len, embed_size\n",
        "\n",
        "    ## Forward\n",
        "    V = self.W_O(V)\n",
        "\n",
        "    return V\n",
        "\n"
      ],
      "metadata": {
        "id": "k0YEsB0hmiyH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class model_architecture(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_size, n_heads, hidden_dim):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    ## Embedding Generation;\n",
        "    self.e1 = nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "    ## Attention layers - Encoder;\n",
        "    self.multi_head_count = 1   ## 12 in the case of GPT\n",
        "    self.attn_layer = nn.ModuleList([attention_layer(n_heads, embed_size) for i in range(self.multi_head_count)])\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(embed_size, hidden_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(hidden_dim, embed_size),\n",
        "    )\n",
        "\n",
        "    self.ln1 = nn.LayerNorm(embed_size)\n",
        "\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    for layer in self.attn_layer:\n",
        "      X = layer(X) + X  ##\n",
        "      X = self.ln1(X)\n",
        "\n",
        "    X = self.net(X)  ## feed forward NN\n",
        "    X = self.ln1(X)\n",
        "\n",
        "    return X\n",
        "\n"
      ],
      "metadata": {
        "id": "gtjAPkir3-Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cJvVAwcKGY6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[[1,2,3],\n",
        "                  [1,2,3]],\n",
        "                 [[1,2,3],\n",
        "                  [1,2,3]]], dtype = float)"
      ],
      "metadata": {
        "id": "TLZeGDHUGY8n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "8QEtlYBhGY-n"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(t, dim=-2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiqJDnRZGyDN",
        "outputId": "538ad7ab-5a91-4ea7-af00-e8dfb5f04e40"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.5000, 0.5000, 0.5000],\n",
              "         [0.5000, 0.5000, 0.5000]],\n",
              "\n",
              "        [[0.5000, 0.5000, 0.5000],\n",
              "         [0.5000, 0.5000, 0.5000]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.0900 + 0.2447 + 0.6652"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb4oOIzTHItJ",
        "outputId": "50e77191-281e-4cef-ad62-a7f98a11d21f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vmEylXlLHNhD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}